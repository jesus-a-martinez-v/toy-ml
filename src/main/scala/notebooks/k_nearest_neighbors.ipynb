{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _k_-Nearest Neighbors\n",
    "\n",
    "_k_-Nearest Neighbors must be one of the most intuitive algorithms to grasp. \n",
    "\n",
    "Unlike **Linear regression** or **Perceptron**, it doesn't use the data to train some hidden model or equation. In fact, the training process of _k_-Nearest Neighbors doesn't involve any calculation. Basically, it holds the training set as a database used at test time to compare new instances of the data to the previous ones and then determine a class (classification) or value (regression) for it, based on some measure of similarity (usually Euclidean distance).\n",
    "\n",
    "Of course, this very trait of _k_-Nearest Neighbors acts against itself at prediction time because it must compare the new instance to all of those it has stored in its database in order to select the _k_ most similar. Hence, the bigger the data used to train the algorithm, the slower the predictions will be.\n",
    "\n",
    "Once the _k_ most similar neighbors have been found, usually, depending on the case, the following actions is taken:\n",
    "\n",
    " - __Classification__: Label the new instance with the most common class among the neighbors. There are variations of this, where the class is selected as a result of a weighted votation where, for instance, nearest neighbors have a higher contribution to the outcome.\n",
    " - __Regression__: Calculate some measure of central tendency (mean, mode, median) from the neighbors' values. \n",
    " \n",
    "Let's start our implementation by loading the code and libraries we'll need. We will build our solution on top of the ones we implemented in the [previous notebook](https://github.com/jesus-a-martinez-v/toy-ml/blob/master/src/main/scala/notebooks/naive_bayes.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling NaiveBayes.sc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$                                     , NaiveBayes._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.5`\n",
    "import $file.^.datasmarts.ml.toy.scripts.NaiveBayes, NaiveBayes._\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We'll use the [Abalone](http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data) dataset. It involves the prediction of the age of abalones given objective measures of individuals. Although it is initially a multiclass classification problem, we'll use it as well as a regression one.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 4177\n",
      "Number of columns in dataset: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mBASE_DATA_PATH\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data\"\u001b[39m\n",
       "\u001b[36mabalonePath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data/13/abalone.data.csv\"\u001b[39m\n",
       "\u001b[36mrawData\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Text(M),\n",
       "    Text(0.455),\n",
       "    Text(0.365),\n",
       "    Text(0.095),\n",
       "    Text(0.514),\n",
       "    Text(0.2245),\n",
       "    Text(0.101),\n",
       "    Text(0.15),\n",
       "    Text(15)\n",
       "  ),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mnumberOfRows\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m4177\u001b[39m\n",
       "\u001b[36mnumberOfColumns\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m9\u001b[39m\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(0.0),\n",
       "    Numeric(0.455),\n",
       "    Numeric(0.365),\n",
       "    Numeric(0.095),\n",
       "    Numeric(0.514),\n",
       "    Numeric(0.2245),\n",
       "    Numeric(0.101),\n",
       "    Numeric(0.15),\n",
       "    Numeric(15.0)\n",
       "  ),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlookUpTable\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mData\u001b[39m, \u001b[32mInt\u001b[39m] = \u001b[33mMap\u001b[39m(Text(M) -> \u001b[32m0\u001b[39m, Text(F) -> \u001b[32m1\u001b[39m, Text(I) -> \u001b[32m2\u001b[39m)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BASE_DATA_PATH = \"../../resources/data\"\n",
    "val abalonePath = s\"$BASE_DATA_PATH/13/abalone.data.csv\"\n",
    "\n",
    "val rawData = loadCsv(abalonePath)\n",
    "val numberOfRows = rawData.length\n",
    "val numberOfColumns = rawData.head.length\n",
    "println(s\"Number of rows in dataset: $numberOfRows\")\n",
    "println(s\"Number of columns in dataset: $numberOfColumns\")\n",
    "\n",
    "val (data, lookUpTable) = {\n",
    "    val dataWithNumericColumns = (1 until numberOfColumns).toVector.foldLeft(rawData) { (d, i) => textColumnToNumeric(d, i)}\n",
    "    categoricalColumnToNumeric(dataWithNumericColumns, 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance\n",
    "\n",
    "In this notebook we'll use Euclidean distance as a similarity measure between two rows or vectors. Here's the equation:\n",
    "\n",
    "$$ distance(X,Y) = \\sqrt{\\sum_{i=1}^n{(X_i - Y_i)^2}}$$\n",
    "\n",
    "Let's implement a function to calculate this measure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36meuclideanDistance\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def euclideanDistance(firstRow: Vector[Numeric], secondRow: Vector[Numeric]) = {\n",
    "  assert(firstRow.length == secondRow.length)\n",
    "\n",
    "  math.sqrt {\n",
    "    val featureIndices = firstRow.indices.init\n",
    "\n",
    "    featureIndices.foldLeft(0.0) { (accum, i) =>\n",
    "      accum + math.pow(firstRow(i).value - secondRow(i).value, 2)\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. Let's test it with a mock dataset:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.3290173915275787\n",
      "1.9494646655653247\n",
      "1.5591439385540549\n",
      "0.5356280721938492\n",
      "4.850940186986411\n",
      "2.592833759950511\n",
      "4.214227042632867\n",
      "6.522409988228337\n",
      "4.985585382449795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmockDataset\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mNumeric\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.7810836\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.550537003\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.465489372\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.362125076\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.396561688\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m4.400293529\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.38807019\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.850220317\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.06407232\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.005305973\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.627531214\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.759262235\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m5.332441248\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.088626775\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m6.922596716\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.77106367\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m8.675418651\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m-0.242068655\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.673756466\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.508563011\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m))\n",
       ")\n",
       "\u001b[36mtestRow\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mNumeric\u001b[39m] = \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.7810836\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.550537003\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mockDataset = Vector(\n",
    "  (2.7810836, 2.550537003, 0),\n",
    "  (1.465489372, 2.362125076, 0),\n",
    "  (3.396561688, 4.400293529, 0),\n",
    "  (1.38807019, 1.850220317, 0),\n",
    "  (3.06407232, 3.005305973, 0),\n",
    "  (7.627531214, 2.759262235, 1),\n",
    "  (5.332441248, 2.088626775, 1),\n",
    "  (6.922596716, 1.77106367, 1),\n",
    "  (8.675418651, -0.242068655, 1),\n",
    "  (7.673756466, 3.508563011, 1)\n",
    ") map { case (x1, x2, y) => Vector(Numeric(x1), Numeric(x2), Numeric(y))}\n",
    "\n",
    "val testRow = mockDataset.head\n",
    "\n",
    "mockDataset.foreach { r => \n",
    "    println(euclideanDistance(testRow, r))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good it works as expected. \n",
    "\n",
    "## Get Neighbors\n",
    "\n",
    "Now that we have a way to calculate distance between rows, the next step is to pick the nearest _k_ neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetNeighbors\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getNeighbors(train: Dataset, testRow: Vector[Numeric], numberOfNeighbors: Int) = {\n",
    "  val neighborsAndDistances = for {\n",
    "    row <- train\n",
    "    numericRow = row.asInstanceOf[Vector[Numeric]]\n",
    "  } yield {\n",
    "    val distance = euclideanDistance(numericRow, testRow)\n",
    "    (numericRow, distance)\n",
    "  }\n",
    "\n",
    "  neighborsAndDistances.sortBy(_._2).take(numberOfNeighbors).map(_._1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the 3 nearest neighbors of our test row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mneighbors\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mNumeric\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.7810836\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.550537003\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.06407232\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.005305973\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.465489372\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.362125076\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val neighbors = getNeighbors(mockDataset, testRow, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We're all set to make predictions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "This time we'll test our algorithm in both classification and regression problems. For that matter we need prediction functions for both cases:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredictClassification\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredictRegression\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predictClassification(train: Dataset, testRow: Vector[Numeric], numberOfNeighbors: Int) = {\n",
    "  val neighbors = getNeighbors(train, testRow, numberOfNeighbors)\n",
    "  val outputValues = neighbors.map(_.last)\n",
    "\n",
    "  outputValues.maxBy(o => outputValues.count(_ == o))\n",
    "}\n",
    "\n",
    "def predictRegression(train: Dataset, testRow: Vector[Numeric], numberOfNeighbors: Int) = {\n",
    "  val neighbors = getNeighbors(train, testRow, numberOfNeighbors)\n",
    "  val outputValues = neighbors.map(_.last)\n",
    "\n",
    "  Numeric {\n",
    "    outputValues.foldLeft(0.0) { (total, numeric) => total + numeric.value } / outputValues.length\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, for classification we are implementing a simply majority voting algorithm, while for regression we selected _mean_ as the measure of central tendency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mPredictor\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mkNearestNeighbors\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Predictor = (Dataset, Vector[Numeric], Int) => Numeric\n",
    "def kNearestNeighbors(train: Dataset, test: Dataset, parameters: Parameters) = {\n",
    "  val numberOfNeighbors = parameters(\"numberOfNeighbors\").asInstanceOf[Int]\n",
    "  val predictor = parameters(\"predictor\").asInstanceOf[Predictor]\n",
    "  \n",
    "  test.map { row =>\n",
    "   predictor(train, row.asInstanceOf[Vector[Numeric]], numberOfNeighbors)\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good.\n",
    "\n",
    "Let's now use our new algorithm to test it on the Abalone dataset.\n",
    "\n",
    "We'll start by running a baseline model on it and then our freshly implemented k-Nearest Neighbors algorithm and then we will compare their performance.\n",
    "\n",
    "As a baseline for classification we will use a __zero rule classifier__, and for regression a __zero rule regressor__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Rule Algorithm accuracy: 0.14952153110047847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mminMax\u001b[39m: \u001b[32mMinMaxData\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0\u001b[39m, \u001b[32m2.0\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.075\u001b[39m, \u001b[32m0.815\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.055\u001b[39m, \u001b[32m0.65\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0\u001b[39m, \u001b[32m1.13\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.002\u001b[39m, \u001b[32m2.8255\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.001\u001b[39m, \u001b[32m1.488\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m5.0E-4\u001b[39m, \u001b[32m0.76\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0015\u001b[39m, \u001b[32m1.005\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m1.0\u001b[39m, \u001b[32m29.0\u001b[39m))\n",
       ")\n",
       "\u001b[36mnormalizedData\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(0.0),\n",
       "    Numeric(0.5135135135135135),\n",
       "    Numeric(0.5210084033613446),\n",
       "    Numeric(0.084070796460177),\n",
       "    Numeric(0.18133522224189835),\n",
       "    Numeric(0.15030262273032952),\n",
       "    Numeric(0.13232389730085584),\n",
       "    Numeric(0.14798206278026907),\n",
       "    Numeric(0.5)\n",
       "  ),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mbaselineAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.14952153110047847\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Normalize data\n",
    "val minMax = getDatasetMinAndMax(data)\n",
    "val normalizedData = normalizeDataset(data, minMax)\n",
    "\n",
    "val baselineAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "        normalizedData, \n",
    "        (train, test, parameters) => zeroRuleClassifier(train, test), \n",
    "        Map.empty, \n",
    "        accuracy, \n",
    "        trainProportion=0.8)\n",
    "\n",
    "println(s\"Zero Rule Algorithm accuracy: $baselineAccuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors accuracy: 0.20574162679425836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mkNearestNeighborsAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.20574162679425836\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val kNearestNeighborsAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "    normalizedData,\n",
    "    kNearestNeighbors,\n",
    "    Map(\"numberOfNeighbors\" -> 5, \"predictor\" -> predictClassification _),\n",
    "    accuracy,\n",
    "    trainProportion=0.8)\n",
    "\n",
    "println(s\"k-Nearest Neighbors accuracy: $kNearestNeighborsAccuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Rule Algorithm RMSE: 0.11533507708591567\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mbaselineRmse\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.11533507708591567\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baselineRmse = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "        normalizedData, \n",
    "        (train, test, parameters) => zeroRuleRegressor(train, test), \n",
    "        Map.empty, \n",
    "        rootMeanSquaredError, \n",
    "        trainProportion=0.8)\n",
    "\n",
    "println(s\"Zero Rule Algorithm RMSE: $baselineRmse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-Nearest Neighbors RMSE: 0.08299764762202569\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mkNearestNeighborsRmse\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.08299764762202569\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val kNearestNeighborsRmse = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "    normalizedData,\n",
    "    kNearestNeighbors,\n",
    "    Map(\"numberOfNeighbors\" -> 5, \"predictor\" -> predictRegression _),\n",
    "    rootMeanSquaredError,\n",
    "    trainProportion=0.8)\n",
    "\n",
    "println(s\"k-Nearest Neighbors RMSE: $kNearestNeighborsRmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, in both cases the baseline and the k-Nearest Neighbors algorithm don't perform as well as expected due to the intricacy of the dataset. Although at first glance the target is numeric, in reality it is ordinal given that what's being predicted is the age of the abalones from several input measures, and none of our motdels seem to be capturing that nuance. Nonetheless, this case study serves our purpose of demonstrating the power and usefulness of the most popular instance-based machine learning algorithm: _k_-Nearest Neighbors.\n",
    "\n",
    "It is very likely that tweaking the number of neighbors and experimenting with some data preprocessing techniques you could bump up the performance. Want to try? :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
