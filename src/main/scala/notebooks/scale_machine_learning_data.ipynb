{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Machine Learning Data\n",
    "\n",
    "An important number of machine learning algorithms make assumptions about the scale of the data and their range of values.\n",
    "\n",
    "Popular algorithms such as **logistic** and **linear regression** put different weights on their parameters, so a scaling problem could really hurt their performance or learning process.\n",
    "\n",
    "Other more complex algorithms such as **artificial neural networks** tend to combine their inputs in non trivial ways. Hence, again, it is a good idea to put all inputs in a similar scale, which could also prevent problems such as exploding or vanishing gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize Data\n",
    "\n",
    "Let's start by exploring one of the two methods for data scaling that we'll address in this notebook: Normalization. \n",
    "\n",
    "Normalization's meaning vary depending on the context. In our context it means that we'll rescale our values to be in the range [0, 1]. We can achieve this by applying the following formula:\n",
    "\n",
    "$$ value' = \\frac{value - min}{max - min} $$\n",
    "\n",
    "Good, let's start our implementation by loading the code and libraries we'll need. We will build our solution on top of the ones we implemented in the [previous notebook](https://github.com/jesus-a-martinez-v/toy-ml/blob/master/src/main/scala/notebooks/load_data_from_csv.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$                                  , LoadCsv._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.5`\n",
    "import $file.^.datasmarts.ml.toy.scripts.LoadCsv, LoadCsv._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's define some type aliases and helper functions to make our lives easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mDataset\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mMinMaxData\u001b[39m\n",
       "defined \u001b[32mtype\u001b[39m \u001b[36mStatisticData\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36misNumeric\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36misText\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetNumericValue\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetTextValue\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Dataset = Vector[Vector[Data]]\n",
    "type MinMaxData = Vector[Option[(Double, Double)]]\n",
    "type StatisticData = Vector[Option[Double]]\n",
    "\n",
    "def isNumeric(data: Data) = data match {\n",
    "  case _: Numeric => true\n",
    "  case _ => false\n",
    "}\n",
    "\n",
    "def isText(data: Data) = !isNumeric(data)\n",
    "\n",
    "\n",
    "def getNumericValue(data: Data): Option[Double] = data match {\n",
    "  case Numeric(value) => Some(value)\n",
    "  case _ => None\n",
    "}\n",
    "\n",
    "def getTextValue(data: Data): Option[String] = data match {\n",
    "  case Text(value) => Some(value)\n",
    "  case _ => None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Our **Dataset** representation is just a vector or rows, where each row is also a vector that contains an entry for each specific column.\n",
    "\n",
    "In order to determine the minimum and maximum value of each column in the dataset, we define the **MinMax** type as a Vector of optional tuples of doubles, where the first element in the tuple corresponds to the minimum and the second to the maximum. Why optional? If a column is not numeric, then we'll return None stating that min and max aren't well defined for text data.\n",
    "\n",
    "Analogously, **StatisticData** type refers to a vector of optional doubles. As in the **MinMax** case, a None represents that either the mean or the standard deviation of a text data cannot be calculated.\n",
    "\n",
    "Finally, **isNumeric**, **isText**, **getNumericValue** and **getTextValue** allow us to determine the type of a data instance, and to get its value, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mock dataset\n",
    "\n",
    "Let's use the following dataset for testing our upcoming functions:\n",
    "\n",
    "| X1 \t|  X2  | X3   |\n",
    "|:---:\t|:----:| :--: |\n",
    "|   50 \t|  30  |   A  |\n",
    "|   20  |  90  |   B  |\n",
    "|   19  | 90.4 |   C  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mdataset\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(Numeric(50.0), Numeric(30.0), Text(A)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(20.0), Numeric(90.0), Text(B)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(19.0), Numeric(90.4), Text(C))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataset: Dataset = Vector(\n",
    "    //       X1            X2          X3\n",
    "    Vector(Numeric(50), Numeric(30), Text(\"A\")),\n",
    "    Vector(Numeric(20), Numeric(90), Text(\"B\")),\n",
    "    Vector(Numeric(19), Numeric(90.4), Text(\"C\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MIN and MAX values of a dataset\n",
    "\n",
    "Let's now proceed to define a function to obtain the minimum and maximum values of each column in a dataset. The logic will be as follows:\n",
    "    \n",
    "    - If the dataset is empty, do nothing.\n",
    "    - If not, for each column:\n",
    "        - If the column is of type Text, then return None.\n",
    "        - If the column is of type Numeric, sort its values in ascending order. The minimum value will be at the beginning of the vector and the maximum at the end. Return them in a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetDatasetMinAndMax\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDatasetMinAndMax(dataset: Dataset): MinMaxData = {\n",
    "  if (dataset.isEmpty) {\n",
    "    Vector.empty\n",
    "  } else {\n",
    "    val numberOfColumns = dataset.head.length\n",
    "    val columnIndicesRange = (0 until numberOfColumns).toVector\n",
    "    val testRow = dataset.head\n",
    "\n",
    "    for {\n",
    "      columnIndex <- columnIndicesRange\n",
    "    } yield {\n",
    "      if (isText(testRow(columnIndex))) {\n",
    "        None\n",
    "      } else {\n",
    "        val columnValues = dataset.map { row => \n",
    "          getNumericValue(row(columnIndex)).get\n",
    "        }.sorted\n",
    "        \n",
    "        val max = columnValues.last\n",
    "        val min = columnValues.head\n",
    "\n",
    "        Some((min, max))\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good! Let's now test it in our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mminMax\u001b[39m: \u001b[32mMinMaxData\u001b[39m = \u001b[33mVector\u001b[39m(\u001b[33mSome\u001b[39m((\u001b[32m19.0\u001b[39m, \u001b[32m50.0\u001b[39m)), \u001b[33mSome\u001b[39m((\u001b[32m30.0\u001b[39m, \u001b[32m90.4\u001b[39m)), None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val minMax = getDatasetMinAndMax(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the results are:\n",
    "\n",
    "|  \t    |  MIN | MAX  |\n",
    "|:---:\t|:----:| :--: |\n",
    "|   **X1** \t|  19  |   50  |\n",
    "|   **X2**  |  30  |   90.4  |\n",
    "|   **X3**  | - |   -  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIN-MAX normalizer\n",
    "\n",
    "We are all set! Let's define a function to calculate the min-max normalization for each value in the dataset. This will only affect Numeric data. Text will remain untouched:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mnormalizeDataset\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalizeDataset(dataset: Dataset, minMaxes: MinMaxData): Dataset = {\n",
    "  if (dataset.isEmpty) {\n",
    "    Vector.empty\n",
    "  } else {\n",
    "    val numberOfColumns = dataset.head.length\n",
    "    val columnIndicesRange = (0 until numberOfColumns).toVector\n",
    "\n",
    "    for {\n",
    "      row <- dataset\n",
    "    } yield {\n",
    "      columnIndicesRange.map { columnIndex =>\n",
    "        val rowData = row(columnIndex)\n",
    "\n",
    "        minMaxes(columnIndex) match {\n",
    "          case None => rowData\n",
    "          case Some((min, max)) =>\n",
    "            val rowValue = getNumericValue(rowData).get\n",
    "            val normalizedRowValue = (rowValue - min) / (max - min)\n",
    "\n",
    "            Numeric(normalizedRowValue)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test it in our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mminMaxNormalizedData\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(Numeric(1.0), Numeric(0.0), Text(A)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(0.03225806451612903), Numeric(0.9933774834437085), Text(B)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(0.0), Numeric(1.0), Text(C))\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val minMaxNormalizedData = normalizeDataset(dataset, minMax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results after normalization are:\n",
    "\n",
    "| X1 \t|  X2  | X3   |\n",
    "|:---:\t|:----:| :--: |\n",
    "|   1 \t|  0  |   A  |\n",
    "|   0.033  |  0.994  |   B  |\n",
    "|   0  | 1 |   C  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize Data\n",
    "\n",
    "The second method for normalizing data is known as _standardization_. This is a rescaling technique that aims to centering the distribution of the data on the value 0 and the standard deviation to 1. These two indicators can be used in conjunction to summarize a normal or Gaussian distribution.\n",
    "\n",
    "The formula for the mean is:\n",
    "\n",
    "$$ \\mu = \\frac{\\sum_{i=1}^{N} value_i}{N}$$\n",
    "\n",
    "The formula for the standard deviation is:\n",
    "\n",
    "$$ \\sigma = \\sqrt{\\frac{\\sum_{i=1}^{N} (value_i - \\mu)^2}{N - 1}} $$\n",
    "\n",
    "And finally, the formula for the standardization is:\n",
    "\n",
    "$$ value' = \\frac{value - \\mu}{\\sigma}  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting MEAN and STANDARD DEVIATIONS of a dataset\n",
    "\n",
    "Let's now proceed to define the functions needed to obtain the mean and standard deviation of each column in a dataset. The logic will be as follows:\n",
    "    \n",
    "    - If the dataset is empty, do nothing.\n",
    "    - If not, for each column:\n",
    "        - If the column is of type Text, then return None.\n",
    "        - If the column is of type Numeric, apply the corresponding formula to obtain the needed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetColumnMeans\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getColumnMeans(dataset: Dataset): StatisticData = {\n",
    "  if (dataset.isEmpty) {\n",
    "    Vector.empty\n",
    "  } else {\n",
    "    val numberOfColumns = dataset.head.length\n",
    "    val testRow = dataset.head\n",
    "\n",
    "    for {\n",
    "      columnIndex <- (0 until numberOfColumns).toVector\n",
    "    } yield {\n",
    "      if (isText(testRow(columnIndex))) {\n",
    "        None\n",
    "      } else {\n",
    "        val columnValues = dataset.map { row => \n",
    "            getNumericValue(row(columnIndex)).get\n",
    "        }\n",
    "        val sum = columnValues.sum\n",
    "        val count = columnValues.length\n",
    "\n",
    "        Some(sum / count)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test it in our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mmeans\u001b[39m: \u001b[32mStatisticData\u001b[39m = \u001b[33mVector\u001b[39m(\u001b[33mSome\u001b[39m(\u001b[32m29.666666666666668\u001b[39m), \u001b[33mSome\u001b[39m(\u001b[32m70.13333333333334\u001b[39m), None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val means = getColumnMeans(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are:\n",
    "\n",
    "|  \t    |  $$ \\mu $$ |\n",
    "|:---:\t|:----:|\n",
    "|   **X1** \t|  29.667  |\n",
    "|   **X2**  |  70.134  |\n",
    "|   **X3**  | - |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetColumnsStandardDeviations\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getColumnsStandardDeviations(dataset: Dataset, means: StatisticData): StatisticData = {\n",
    "  if (dataset.isEmpty) {\n",
    "    Vector.empty\n",
    "  } else {\n",
    "    val numberOfColumns = dataset.head.length\n",
    "    val testRow = dataset.head\n",
    "      \n",
    "    for {\n",
    "      columnIndex <- (0 until numberOfColumns).toVector\n",
    "      \n",
    "    } yield {\n",
    "      if (isText(testRow(columnIndex))) {\n",
    "        None\n",
    "      } else {\n",
    "        val columnMean = means(columnIndex).get\n",
    "        val columnSquaredMeanDifferences = dataset.map { row => \n",
    "            val meanDifference = getNumericValue(row(columnIndex)).get - columnMean\n",
    "            \n",
    "            math.pow(meanDifference, 2)\n",
    "        }\n",
    "        val sum = columnSquaredMeanDifferences.sum\n",
    "        val count = columnSquaredMeanDifferences.length\n",
    "        val variance = sum / (count - 1)\n",
    "        val standardDeviation = math.sqrt(variance)\n",
    "\n",
    "        Some(standardDeviation)\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test it in our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mstandardDeviations\u001b[39m: \u001b[32mStatisticData\u001b[39m = \u001b[33mVector\u001b[39m(\u001b[33mSome\u001b[39m(\u001b[32m17.61628034896508\u001b[39m), \u001b[33mSome\u001b[39m(\u001b[32m34.757061632614075\u001b[39m), None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val standardDeviations = getColumnsStandardDeviations(dataset, means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are:\n",
    "\n",
    "|  \t    |  $$ \\sigma $$ |\n",
    "|:---:\t|:----:|\n",
    "|   **X1** \t|  17.616  |\n",
    "|   **X2** |  34.757  |\n",
    "|   **X3**  | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's use these functions to standardize a dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mstandardizeDataset\u001b[39m"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardizeDataset(dataset: Dataset, means: StatisticData, standardDeviations: StatisticData): Dataset = {\n",
    "  if (dataset.isEmpty) {\n",
    "    Vector.empty\n",
    "  } else {\n",
    "    val numberOfColumns = dataset.head.length\n",
    "\n",
    "    for {\n",
    "      row <- dataset\n",
    "      columnIndicesRange = (0 until numberOfColumns).toVector\n",
    "    } yield {\n",
    "      columnIndicesRange.map { columnIndex =>\n",
    "        val rowData = row(columnIndex)\n",
    "\n",
    "        if (isText(rowData)) {\n",
    "          rowData\n",
    "        } else {\n",
    "          val columnMean = means(columnIndex).get\n",
    "          val columnStandardDeviation = standardDeviations(columnIndex).get\n",
    "          val rowValue = getNumericValue(rowData).get\n",
    "\n",
    "          val standardizedRowValue = (rowValue - columnMean) / columnStandardDeviation\n",
    "\n",
    "          Numeric(standardizedRowValue)\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now test it in our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mstandardizedDataset\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(Numeric(1.1542353397281098), Numeric(-1.1546814215064278), Text(A)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(-0.5487348336412325), Numeric(0.5715864844001916), Text(B)),\n",
       "  \u001b[33mVector\u001b[39m(Numeric(-0.6055005060868773), Numeric(0.5830949371062358), Text(C))\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val standardizedDataset = standardizeDataset(dataset, means, standardDeviations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results after standardization are:\n",
    "\n",
    "| X1 \t|  X2  | X3   |\n",
    "|:---:\t|:----:| :--: |\n",
    "|   1.154 \t|  -1.155  |   A  |\n",
    "|   -0.549  |  0.572  |   B  |\n",
    "|   -0.606  | 0.583 |   C  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to normalize? When to standardize?\n",
    "\n",
    "When the data or any particular column doesn't follow a normal distribution, it is a good idea to apply MIN-MAX normalization because it doesn't make any assumptions regarding the values' distributions.\n",
    "\n",
    "On the other hand, if the data or any particular column adjust to a Gaussian distribution, standardizing is definitely the way to go!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
