{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron\n",
    "\n",
    "There's no doubt that neural networks are one of the most potent and powerful machine learning algorithms in today's world. \n",
    "\n",
    "Today we will implement the simplest neural networks possible. It consists of only one neuron and it's called __Perceptron__.\n",
    "\n",
    "The perceptron works great for two-class classification problems. In order to solve more complex tasks many perceptrons can be combined!\n",
    "\n",
    "The perceptron algorithm draws inspiration from the way a single cell, called \"neuron\", processes information. Each neuron accepts input data via its dendrites and pass it as a signal to its body. In a similar fashion, a perceptron takes training examples as input signals and combine it in a linear equation called _activation_, that is defined as follows:\n",
    "\n",
    "$$ activation = bias + \\sum_{i=1}^{N}(weigth * x_i)$$\n",
    "\n",
    "The activation is then thresholded to output a value or prediction.\n",
    "\n",
    "$$ prediction=1.0\\ if\\ activation>=0.0\\ else\\ 0.0 $$\n",
    "\n",
    "In order to determine the _weight_ (just another name for _coefficient_) we use __Gradient Descent__.\n",
    "\n",
    "Let's start our implementation by loading the code and libraries we'll need. We will build our solution on top of the ones we implemented in the [previous notebook](https://github.com/jesus-a-martinez-v/toy-ml/blob/master/src/main/scala/notebooks/logistic_regression.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$                                             , LogisticRegression._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.5`\n",
    "import $file.^.datasmarts.ml.toy.scripts.LogisticRegression, LogisticRegression._\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We'll use the [Sonar](https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data) dataset. It involves the prediction of whether or not a certain object is a mine or a rock given the strength of sonar returns at various angles. It is, of course, a binary classification problem, perfect for our perceptron.\n",
    "\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 208\n",
      "Number of column in dataset: 61\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mBASE_DATA_PATH\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data\"\u001b[39m\n",
       "\u001b[36msonarPath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data/10/sonar.all-data.csv\"\u001b[39m\n",
       "\u001b[36mrawData\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Text(0.0200),\n",
       "    Text(0.0371),\n",
       "    Text(0.0428),\n",
       "    Text(0.0207),\n",
       "    Text(0.0954),\n",
       "    Text(0.0986),\n",
       "    Text(0.1539),\n",
       "    Text(0.1601),\n",
       "    Text(0.3109),\n",
       "    Text(0.2111),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mnumberOfRows\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m208\u001b[39m\n",
       "\u001b[36mnumberOfColumns\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m61\u001b[39m\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(0.02),\n",
       "    Numeric(0.0371),\n",
       "    Numeric(0.0428),\n",
       "    Numeric(0.0207),\n",
       "    Numeric(0.0954),\n",
       "    Numeric(0.0986),\n",
       "    Numeric(0.1539),\n",
       "    Numeric(0.1601),\n",
       "    Numeric(0.3109),\n",
       "    Numeric(0.2111),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlookUpTable\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mData\u001b[39m, \u001b[32mInt\u001b[39m] = \u001b[33mMap\u001b[39m(Text(R) -> \u001b[32m0\u001b[39m, Text(M) -> \u001b[32m1\u001b[39m)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BASE_DATA_PATH = \"../../resources/data\"\n",
    "val sonarPath = s\"$BASE_DATA_PATH/10/sonar.all-data.csv\"\n",
    "\n",
    "val rawData = loadCsv(sonarPath)\n",
    "val numberOfRows = rawData.length\n",
    "val numberOfColumns = rawData.head.length\n",
    "println(s\"Number of rows in dataset: $numberOfRows\")\n",
    "println(s\"Number of column in dataset: $numberOfColumns\")\n",
    "\n",
    "val (data, lookUpTable) = {\n",
    "    val dataWithNumericColumns = (0 until (numberOfColumns - 1)).toVector.foldLeft(rawData) { (d, i) => textColumnToNumeric(d, i)}\n",
    "    categoricalColumnToNumeric(dataWithNumericColumns, numberOfColumns - 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions\n",
    "\n",
    "Let's proceed to implement a function that makes prediction on a row, given some fitted weights. This will be very useful during the training phase as well as in the test stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredictWithWeights\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predictWithWeights(row: Vector[Data], weights: Vector[Double]) = {\n",
    "  val indices = row.indices.init\n",
    "\n",
    "  val activation = indices.foldLeft(0.0) { (accumulator, index) =>\n",
    "    accumulator + weights(index + 1) * getNumericValue(row(index)).get\n",
    "  } + weights.head\n",
    "\n",
    "  if (activation >= 0.0) 1.0 else 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it on a mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.0, Predicted=0.0\n",
      "Expected=0.0, Predicted=0.0\n",
      "Expected=0.0, Predicted=0.0\n",
      "Expected=0.0, Predicted=0.0\n",
      "Expected=0.0, Predicted=0.0\n",
      "Expected=1.0, Predicted=1.0\n",
      "Expected=1.0, Predicted=1.0\n",
      "Expected=1.0, Predicted=1.0\n",
      "Expected=1.0, Predicted=1.0\n",
      "Expected=1.0, Predicted=1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmockDataset\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mNumeric\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.7810836\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.550537003\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.465489372\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.362125076\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.396561688\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m4.400293529\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.38807019\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.850220317\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.06407232\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.005305973\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.627531214\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.759262235\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m5.332441248\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.088626775\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m6.922596716\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.77106367\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m8.675418651\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m-0.242068655\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.673756466\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.508563011\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m))\n",
       ")\n",
       "\u001b[36mmockWeigths\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mVector\u001b[39m(\u001b[32m-0.1\u001b[39m, \u001b[32m0.20653640140000007\u001b[39m, \u001b[32m-0.23418117710000003\u001b[39m)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mockDataset = Vector(\n",
    "    (2.7810836, 2.550537003,0),\n",
    "    (1.465489372, 2.362125076, 0),\n",
    "    (3.396561688, 4.400293529, 0),\n",
    "    (1.38807019, 1.850220317, 0),\n",
    "    (3.06407232, 3.005305973, 0),\n",
    "    (7.627531214, 2.759262235, 1),\n",
    "    (5.332441248, 2.088626775, 1),\n",
    "    (6.922596716, 1.77106367, 1),\n",
    "    (8.675418651,-0.242068655, 1),\n",
    "    (7.673756466, 3.508563011, 1)).map{ case (x1, x2, y) => Vector(Numeric(x1), Numeric(x2), Numeric(y)) }\n",
    "\n",
    "val mockWeigths = Vector(-0.1, 0.20653640140000007, -0.23418117710000003)\n",
    "\n",
    "mockDataset.foreach { case row @ Vector(Numeric(x1), Numeric(x2), Numeric(y)) => \n",
    "    val predicted = predictWithWeights(row, mockWeigths)\n",
    "    println(s\"Expected=$y, Predicted=$predicted\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to implement stochastic gradient descent to train the weights of the perceptron. Let's do it.\n",
    "\n",
    "## Estimating Weights\n",
    "\n",
    "Now that we have a predicting function in place, the next step is to implement a function to estimate the weights that'll be used later on in the pipeline:\n",
    "\n",
    "We are implementing Stochastic Gradient Descent. It requires two parameters:\n",
    "\n",
    " - __Learning Rate__: It is used to control the amount of correction each parameter will receive at a time.\n",
    " - __Number of epochs__: Number of times the algorithm will loop over all the data, updating the weights.\n",
    " \n",
    "The outline of the algorithm is as follows:\n",
    "\n",
    " 1. Loop over each epoch.\n",
    " 2. Loop over each row in the training set.\n",
    " 3. Loop over each weigth and update it for a row in an epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtrainWeights\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trainWeights(train: Dataset, learningRate: Double, numberOfEpochs: Int) = {\n",
    "  var weights = Vector.fill(train.head.length)(0.0)\n",
    "\n",
    "  for {\n",
    "    _ <- 1 to numberOfEpochs\n",
    "    row <- train\n",
    "  } {\n",
    "\n",
    "    val predicted = predictWithWeights(row, weights)\n",
    "    val actual = getNumericValue(row.last).get\n",
    "    val error = actual - predicted\n",
    "\n",
    "    val bias = weights.head + learningRate * error\n",
    "    val indices = row.indices.init\n",
    "\n",
    "    val remainingWeights = indices.foldLeft(weights) { (w, index) =>\n",
    "      val actual = getNumericValue(row(index)).get\n",
    "      updatedVector(w, w(index + 1) + learningRate * error * actual, index + 1)\n",
    "    }\n",
    "\n",
    "    weights = Vector(bias) ++ remainingWeights.tail\n",
    "  }\n",
    "\n",
    "  weights\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the weights for our mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres5\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mDouble\u001b[39m] = \u001b[33mVector\u001b[39m(\u001b[32m-0.1\u001b[39m, \u001b[32m0.20653640140000007\u001b[39m, \u001b[32m-0.23418117710000003\u001b[39m)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainWeights(mockDataset, 0.1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron\n",
    "\n",
    "We have all that we need to implement a simple perceptron algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mperceptron\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def perceptron(train: Dataset, test: Dataset, parameters: Parameters) = {\n",
    "  val learningRate = parameters(\"learningRate\").asInstanceOf[Double]\n",
    "  val numberOfEpochs = parameters(\"numberOfEpochs\").asInstanceOf[Int]\n",
    "\n",
    "  val weights = trainWeights(train, learningRate, numberOfEpochs)\n",
    "\n",
    "  test.map { row =>\n",
    "    Numeric(predictWithWeights(row, weights))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. We just need to unpack the relevant parameters, use SGD to obtain the weights and then use them to make predictions on the test set.\n",
    "\n",
    "Let's now use our new algorithm to test it on the Sinar dataset.\n",
    "\n",
    "We'll start by running a baseline model on it and then our freshly implemented perceptron algorithm and then we will compare their performance.\n",
    "\n",
    "As a baseline we will use a __zero rule classifier__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Algorithm accuracy: 0.5714285714285714\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mminMax\u001b[39m: \u001b[32mMinMaxData\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0015\u001b[39m, \u001b[32m0.1371\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m6.0E-4\u001b[39m, \u001b[32m0.2339\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0015\u001b[39m, \u001b[32m0.3059\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0058\u001b[39m, \u001b[32m0.4264\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0067\u001b[39m, \u001b[32m0.401\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0102\u001b[39m, \u001b[32m0.3823\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0033\u001b[39m, \u001b[32m0.3729\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0055\u001b[39m, \u001b[32m0.459\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0075\u001b[39m, \u001b[32m0.6828\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0113\u001b[39m, \u001b[32m0.7106\u001b[39m)),\n",
       "  \u001b[33mSome\u001b[39m((\u001b[32m0.0289\u001b[39m, \u001b[32m0.7342\u001b[39m)),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mnormalizedData\u001b[39m: \u001b[32mDataset\u001b[39m = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(0.1364306784660767),\n",
       "    Numeric(0.15645092156022286),\n",
       "    Numeric(0.13567674113009198),\n",
       "    Numeric(0.03542558250118878),\n",
       "    Numeric(0.22495561755008875),\n",
       "    Numeric(0.2375705455522709),\n",
       "    Numeric(0.40746753246753253),\n",
       "    Numeric(0.3409040793825799),\n",
       "    Numeric(0.44928180068117873),\n",
       "    Numeric(0.2857142857142857),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mbaselineAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.5714285714285714\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Normalize data\n",
    "val minMax = getDatasetMinAndMax(data)\n",
    "val normalizedData = normalizeDataset(data, minMax)\n",
    "\n",
    "val baselineAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "        normalizedData, \n",
    "        (train, test, parameters) => zeroRuleClassifier(train, test), \n",
    "        Map.empty, \n",
    "        accuracy, \n",
    "        trainProportion=0.8)\n",
    "\n",
    "println(s\"Random Algorithm accuracy: $baselineAccuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron accuracy: 0.7857142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mperceptronAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.7857142857142857\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val perceptronAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "        normalizedData, \n",
    "        perceptron, \n",
    "        Map(\"learningRate\" -> 0.01, \"numberOfEpochs\" -> 500), \n",
    "        accuracy, \n",
    "        trainProportion=0.8)\n",
    "\n",
    "println(s\"Perceptron accuracy: $perceptronAccuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite noticeable that the difference in performance is remarkable.\n",
    "\n",
    "As happens with many of the algorithms that belong to the _regression family_, the perceptron is very simple at its core, but it is very powerful when used in the right context.\n",
    "\n",
    "Moreover, a perceptron is the basic building block of really complex architectures that are pushing forward the boundaries of machine learning and AI in general. \n",
    "\n",
    "Such enterprises as self-driving cars, flying cars, robot assistants, face recognition systems (and many more) implement complex neural networks that, in the end, are just composites of many units similar to the perceptron that are expert at noticing a particular feature in the data.\n",
    "\n",
    "Quite exciting, huh? ;)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
