{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "Decision trees are one of the most powerful and popular prediction methods used nowadays. They are used in many fields and are the basis of more powerful techniques such as __Bagging__ and __Boosting__.\n",
    "\n",
    "One of the biggest selling points of decision trees is that the final model can be understood by experts and novices because, in the end, it consists of a series of rules that comprise a decision graph and, hence, each decision can be tracked through the tree.\n",
    "\n",
    "Although decision trees can be used in regression and classification problems, in this notebook we'll focus on the latter case. For that matter we'll compute something called __Gini index__ or __Gini cost function__ which measures the purity of a particular node in the tree. A node is 100% pure if all the rows or examples that comprise it are of the same class.\n",
    "\n",
    "Let's start our implementation by loading the code and libraries we'll need. We will build our solution on top of the ones we implemented in the [previous notebook](https://github.com/jesus-a-martinez-v/toy-ml/blob/master/src/main/scala/notebooks/linear_vector_quantization.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compiling LinearVectorQuantization.sc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                      \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$file.$                                                   , LinearVectorQuantization._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mscala.util.Random\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.github.tototoshi::scala-csv:1.3.5`\n",
    "import $file.^.datasmarts.ml.toy.scripts.LinearVectorQuantization, LinearVectorQuantization._\n",
    "import scala.util.Random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We'll use the [Banknote](http://archive.ics.uci.edu/ml/machine-learning-databases/00267/data_banknote_authentication.txt) dataset. It involves the prediction of the authenticity of a banknote based on a given number of measures extracted from a photograph. It is a binary classification task.\n",
    "\n",
    "Let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in dataset: 1372\n",
      "Number of columns in dataset: 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mBASE_DATA_PATH\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data\"\u001b[39m\n",
       "\u001b[36mbanknotePath\u001b[39m: \u001b[32mString\u001b[39m = \u001b[32m\"../../resources/data/11/banknote.csv\"\u001b[39m\n",
       "\u001b[36mrawData\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(Text(3.6216), Text(8.6661), Text(-2.8073), Text(-0.44699), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(4.5459), Text(8.1674), Text(-2.4586), Text(-1.4621), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(3.866), Text(-2.6383), Text(1.9242), Text(0.10645), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(3.4566), Text(9.5228), Text(-4.0112), Text(-3.5944), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(0.32924), Text(-4.4552), Text(4.5718), Text(-0.9888), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(4.3684), Text(9.6718), Text(-3.9606), Text(-3.1625), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(3.5912), Text(3.0129), Text(0.72888), Text(0.56421), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(2.0922), Text(-6.81), Text(8.4636), Text(-0.60216), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(3.2032), Text(5.7588), Text(-0.75345), Text(-0.61251), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(1.5356), Text(9.1772), Text(-2.2718), Text(-0.73535), Text(0)),\n",
       "  \u001b[33mVector\u001b[39m(Text(1.2247), Text(8.7779), Text(-2.2135), Text(-0.80647), Text(0)),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mnumberOfRows\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m1372\u001b[39m\n",
       "\u001b[36mnumberOfColumns\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m5\u001b[39m\n",
       "\u001b[36mdata\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mData\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(3.6216),\n",
       "    Numeric(8.6661),\n",
       "    Numeric(-2.8073),\n",
       "    Numeric(-0.44699),\n",
       "    Numeric(0.0)\n",
       "  ),\n",
       "  \u001b[33mVector\u001b[39m(\n",
       "    Numeric(4.5459),\n",
       "    Numeric(8.1674),\n",
       "    Numeric(-2.4586),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mlookUpTable\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mData\u001b[39m, \u001b[32mInt\u001b[39m] = \u001b[33mMap\u001b[39m(Text(0) -> \u001b[32m0\u001b[39m, Text(1) -> \u001b[32m1\u001b[39m)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val BASE_DATA_PATH = \"../../resources/data\"\n",
    "val banknotePath = s\"$BASE_DATA_PATH/11/banknote.csv\"\n",
    "\n",
    "val rawData = loadCsv(banknotePath)\n",
    "val numberOfRows = rawData.length\n",
    "val numberOfColumns = rawData.head.length\n",
    "println(s\"Number of rows in dataset: $numberOfRows\")\n",
    "println(s\"Number of columns in dataset: $numberOfColumns\")\n",
    "\n",
    "val (data, lookUpTable) = {\n",
    "    val dataWithNumericColumns = (0 until (numberOfColumns - 1)).toVector.foldLeft(rawData) { (d, i) => textColumnToNumeric(d, i) }\n",
    "    categoricalColumnToNumeric(dataWithNumericColumns, numberOfColumns - 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gini Index\n",
    "\n",
    "Gini index is the cost function we'll use to determine how good is a split point in the dataset. \n",
    "\n",
    "A split involves a feature and a value for that feature. Then they are used to divide training patterns and nuances into two groups of rows. For instance, if we select feature _X1_ and value _0.5_, then we could have two groups of rows corresponding to __rows where X1 >= 0.5__ and __rows where X1 < 0.5__.\n",
    "\n",
    "Then, the Gini score would be 0.0 if we have the perfect separation among classes and 1.0 if that split left us with the worst separation possible, which is 50/50 presence of each class in each group.\n",
    "\n",
    "Let's implement a Gini index function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtype\u001b[39m \u001b[36mGroup\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mginiIndex\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type Group = Vector[Vector[Data]]  // Just a vector of rows\n",
    "\n",
    "def giniIndex(groups: Vector[Group], classValues: Vector[Numeric]) = {\n",
    "  classValues.foldLeft(0.0) { (accumulatedGini, classValue) =>\n",
    "    groups.foldLeft(accumulatedGini) { (g, group) =>\n",
    "      if (group.nonEmpty) {\n",
    "        val proportion = group.map(_.last).count(_ == classValue).toDouble / group.length.toDouble\n",
    "        g + proportion * (1.0 - proportion)\n",
    "      } else {\n",
    "        g\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Split\n",
    "\n",
    "The first thing we need to do is actually creating a split. Let's start by implementing a function for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtestSplit\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def testSplit(index: Int, value: Numeric, dataset: Dataset): Vector[Vector[Vector[Data]]] = {\n",
    "  val numericValue = value.value\n",
    "  val (left, right) = dataset.partition(r => getNumericValue(r(index)).get < numericValue)\n",
    "\n",
    "  Vector(left, right)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we create two groups based on those rows where the feature is lesser than a specified value and those rows where the feature is greater than or equal to the provided value.\n",
    "\n",
    "Now we need a way of selecting the best split, using our Gini index function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mtrait\u001b[39m \u001b[36mTreeNode\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mInnerNode\u001b[39m\n",
       "defined \u001b[32mclass\u001b[39m \u001b[36mTerminalNode\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mgetSplit\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sealed trait TreeNode\n",
    "case class InnerNode(index: Int, value: Double, groups: Option[Vector[Group]] = None, left: Option[TreeNode] = None, right: Option[TreeNode] = None) extends TreeNode\n",
    "case class TerminalNode(outcome: Numeric) extends TreeNode\n",
    "\n",
    "def getSplit(dataset: Dataset) = {\n",
    "  val classValues = selectColumn(dataset, dataset.head.length - 1).distinct\n",
    "  \n",
    "  var bIndex = 999\n",
    "  var bValue = 999.0\n",
    "  var bScore = 999.0\n",
    "  var bGroups = Vector.empty[Group]\n",
    "\n",
    "  for (index <- 0 until (dataset.head.length - 1)) {\n",
    "    for (row <- dataset) {\n",
    "      val groups = testSplit(index, row(index).asInstanceOf[Numeric], dataset)\n",
    "      val gini = giniIndex(groups, classValues.asInstanceOf[Vector[Numeric]])\n",
    "\n",
    "      if (gini < bScore) {\n",
    "        bIndex = index\n",
    "        bValue = row(index).asInstanceOf[Numeric].value\n",
    "        bScore = gini\n",
    "        bGroups = groups\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "\n",
    "  InnerNode(index = bIndex, value = bValue, groups = Some(bGroups))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we return the best split as an inner node of the tree. Basically, we return the index corresponding to the feature column in the dataset, the splitting value and the rows or group that comprise this split node.\n",
    "\n",
    "Let's test this on a mock dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "6.642287351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mmockDataset\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mNumeric\u001b[39m]] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.771244718\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.784783929\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m1.728571309\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.169761413\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.678319846\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.81281357\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m3.961043357\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.61995032\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m2.999208922\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m2.209014212\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.497545867\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.162953546\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m9.00220326\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.339047188\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m7.444542326\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m0.476683375\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m10.12493903\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.234550982\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m)),\n",
       "  \u001b[33mVector\u001b[39m(\u001b[33mNumeric\u001b[39m(\u001b[32m6.642287351\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m3.319983761\u001b[39m), \u001b[33mNumeric\u001b[39m(\u001b[32m1.0\u001b[39m))\n",
       ")\n",
       "\u001b[36msplit\u001b[39m: \u001b[32mInnerNode\u001b[39m = InnerNode(0,6.642287351,Some(Vector(Vector(Vector(Numeric(2.771244718), Numeric(1.784783929), Numeric(0.0)), Vector(Numeric(1.728571309), Numeric(1.169761413), Numeric(0.0)), Vector(Numeric(3.678319846), Numeric(2.81281357), Numeric(0.0)), Vector(Numeric(3.961043357), Numeric(2.61995032), Numeric(0.0)), Vector(Numeric(2.999208922), Numeric(2.209014212), Numeric(0.0))), Vector(Vector(Numeric(7.497545867), Numeric(3.162953546), Numeric(1.0)), Vector(Numeric(9.00220326), Numeric(3.339047188), Numeric(1.0)), Vector(Numeric(7.444542326), Numeric(0.476683375), Numeric(1.0)), Vector(Numeric(10.12493903), Numeric(3.234550982), Numeric(1.0)), Vector(Numeric(6.642287351), Numeric(3.319983761), Numeric(1.0))))),None,None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val mockDataset = Vector(\n",
    "  (2.771244718,1.784783929,0),\n",
    "  (1.728571309,1.169761413,0),\n",
    "  (3.678319846,2.81281357,0),\n",
    "  (3.961043357,2.61995032,0),\n",
    "  (2.999208922,2.209014212,0),\n",
    "  (7.497545867,3.162953546,1),\n",
    "  (9.00220326,3.339047188,1),\n",
    "  (7.444542326,0.476683375,1),\n",
    "  (10.12493903,3.234550982,1),\n",
    "  (6.642287351,3.319983761,1)) map { case (x1, x2, y) => Vector(Numeric(x1), Numeric(x2), Numeric(y)) }\n",
    "\n",
    "val split = getSplit(mockDataset)\n",
    "println(split.index)\n",
    "println(split.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good. What we see here is that our function decided that the best split for this dataset is on the feature at column 0, on the value 6.642287351."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Tree\n",
    "\n",
    "We've arrived to the hardest part: building the actual tree.\n",
    "\n",
    "A tree is comprised of __terminal nodes__ that are those nodes where we stop expanding based on a preconfigured maximum depth of the tree and the minimum number of rows in a group of a node. Terminal nodes are used to make final predictions. Given that they do not need to know about groups, or subtrees, we will only store on them the outcome (class label).\n",
    "\n",
    "Let's create a function to instantiate a terminal node based on a group of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtoTerminal\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toTerminal(group: Group): TerminalNode = {\n",
    "  val outcomes = group.map(_.last)\n",
    "  TerminalNode {\n",
    "    outcomes.maxBy(o => outcomes.count(_ == o)).asInstanceOf[Numeric]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the outcome is defined as the mode among the labels or classes.\n",
    "\n",
    "Now, for the inner nodes of the tree we must apply a recursive process. Here's the outline of the function that'll do that:\n",
    "\n",
    "  1. We extract the two groups of data split by the node.\n",
    "  2. Then, if either the left or right group is empty, we'll proceed to create a terminal node using the rows we have.\n",
    "  3. If we reached our maximum depth, we create a terminal node.\n",
    "  4. Then, we process the left child creating a terminal node if the group of rows is less than _minimum size_. If not, we make a recursive call on the left group and the depth is incremented by one. Next, we process the right child in the same fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msplit\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split(node: TreeNode, maxDepth: Int, minSize: Int, depth: Int): TreeNode = {\n",
    "  node match {\n",
    "    case terminalNode: TerminalNode =>\n",
    "      terminalNode\n",
    "\n",
    "    case innerNode @ InnerNode(index, value, Some(Vector(leftGroup, rightGroup)), _, _)\n",
    "      if leftGroup.isEmpty || rightGroup.isEmpty =>\n",
    "\n",
    "      val t = toTerminal(leftGroup ++ rightGroup)\n",
    "      innerNode.copy(left = Some(t), right = Some(t))\n",
    "\n",
    "    case innerNode: InnerNode if innerNode.groups.isDefined =>\n",
    "      val groups: Vector[Group] = innerNode.groups.get\n",
    "      val Vector(left, right) = groups\n",
    "\n",
    "      if (depth >= maxDepth) {\n",
    "        innerNode.copy(left = Some(toTerminal(left)), right = Some(toTerminal(right)))\n",
    "      } else {\n",
    "        val leftNode = if (left.lengthCompare(minSize) <= 0) {\n",
    "            innerNode.copy(left = Some(toTerminal(left)))\n",
    "        } else {\n",
    "          val n = innerNode.copy(left = Some(getSplit(left)))\n",
    "          split(n, maxDepth, minSize, depth + 1)\n",
    "        }\n",
    "\n",
    "        val rightNode = if (right.lengthCompare(minSize) <= 0) {\n",
    "          innerNode.copy(right = Some(toTerminal(right)))\n",
    "        } else {\n",
    "          val n = innerNode.copy(right = Some(getSplit(right)))\n",
    "          split(n, maxDepth, minSize, depth + 1)\n",
    "        }\n",
    "\n",
    "        innerNode.copy(left = Some(leftNode), right = Some(rightNode))\n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Tree\n",
    "\n",
    "Building a tree is now only a matter of calling `split` on the whole dataset, and specifying the desired maximum depth and minimum node size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mbuildTree\u001b[39m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def buildTree(train: Dataset, maxDepth: Int, minSize: Int) = split(getSplit(train), maxDepth, minSize, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a little tree using our mock dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres9\u001b[39m: \u001b[32mTreeNode\u001b[39m = InnerNode(0,6.642287351,Some(Vector(Vector(Vector(Numeric(2.771244718), Numeric(1.784783929), Numeric(0.0)), Vector(Numeric(1.728571309), Numeric(1.169761413), Numeric(0.0)), Vector(Numeric(3.678319846), Numeric(2.81281357), Numeric(0.0)), Vector(Numeric(3.961043357), Numeric(2.61995032), Numeric(0.0)), Vector(Numeric(2.999208922), Numeric(2.209014212), Numeric(0.0))), Vector(Vector(Numeric(7.497545867), Numeric(3.162953546), Numeric(1.0)), Vector(Numeric(9.00220326), Numeric(3.339047188), Numeric(1.0)), Vector(Numeric(7.444542326), Numeric(0.476683375), Numeric(1.0)), Vector(Numeric(10.12493903), Numeric(3.234550982), Numeric(1.0)), Vector(Numeric(6.642287351), Numeric(3.319983761), Numeric(1.0))))),Some(TerminalNode(Numeric(0.0))),Some(TerminalNode(Numeric(1.0))))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildTree(mockDataset, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions\n",
    "\n",
    "Making predictions is just the process of traversing the tree, selecting the branches that the different split nodes indicate until we reach a terminal node. Then, the prediction will be the outcome stored in that node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mpredictWithTree\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predictWithTree(node: TreeNode, row: Vector[Numeric]): Numeric = node match {\n",
    "  case TerminalNode(outcome) => outcome\n",
    "  case i: InnerNode =>\n",
    "    if (getNumericValue(row(i.index)).get <= i.value) {\n",
    "      predictWithTree(i.left.get, row)\n",
    "    } else {\n",
    "      predictWithTree(i.right.get, row)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mdecisionTree\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decisionTree(train: Dataset, test: Dataset, parameters: Parameters) = {\n",
    "  val maxDepth = parameters(\"maxDepth\").asInstanceOf[Int]\n",
    "  val minSize = parameters(\"minSize\").asInstanceOf[Int]\n",
    "\n",
    "  val t = buildTree(train, maxDepth, minSize)\n",
    "\n",
    "  test.map { row =>\n",
    "    predictWithTree(t, row.asInstanceOf[Vector[Numeric]])\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make prediction on our mock dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected=0.0, Got=0.0\n",
      "Expected=0.0, Got=0.0\n",
      "Expected=0.0, Got=0.0\n",
      "Expected=0.0, Got=0.0\n",
      "Expected=0.0, Got=0.0\n",
      "Expected=1.0, Got=1.0\n",
      "Expected=1.0, Got=1.0\n",
      "Expected=1.0, Got=1.0\n",
      "Expected=1.0, Got=1.0\n",
      "Expected=1.0, Got=0.0\n"
     ]
    }
   ],
   "source": [
    "for (r <- mockDataset) {\n",
    "  println(s\"Expected=${r.last.value}, Got=${predictWithTree(buildTree(mockDataset, 1, 1), r).value}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good.\n",
    "\n",
    "Let's now use our new algorithm to test it on the Banknote dataset.\n",
    "\n",
    "We'll start by running a baseline model on it and then our freshly implemented Decision Tree algorithm and then we will compare their performance.\n",
    "\n",
    "As a baseline for classification we will use a __zero rule classifier__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zero Rule Algorithm accuracy: 0.5927272727272728\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mbaselineAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.5927272727272728\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val baselineAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "  data,\n",
    "  (train, test, parameters) => zeroRuleClassifier(train, test),\n",
    "  Map.empty,\n",
    "  accuracy,\n",
    "  trainProportion=0.8)\n",
    "\n",
    "println(s\"Zero Rule Algorithm accuracy: $baselineAccuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree accuracy: 0.7818181818181819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mdecisionTreeAccuracy\u001b[39m: \u001b[32mDouble\u001b[39m = \u001b[32m0.7818181818181819\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val decisionTreeAccuracy = evaluateAlgorithmUsingTrainTestSplit[Numeric](\n",
    "  data,\n",
    "  decisionTree,\n",
    "  Map(\"maxDepth\" -> 5, \"minSize\" -> 10),\n",
    "  accuracy,\n",
    "  trainProportion=0.8)\n",
    "\n",
    "println(s\"Decision Tree accuracy: $decisionTreeAccuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great. As expected, our __decision tree__ performs a lot better than our baseline. \n",
    "\n",
    "Of course, playing around with different depths and node sizes could potentially yield a better score, so I encourage you to play and beat my accuracy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
